# -*- coding: utf-8 -*-
"""python_notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kK-x802jVcucVoFp71Qoh-jWkwYIDkGC
"""

import pandas as pd
import seaborn as sns
import numpy as np
import warnings 
warnings.filterwarnings('ignore')
import statsmodels.api as sm
import pylab as plt

regression=pd.read_csv("regression_data.csv",sep= ";")
regression.head()

#Eliminamos la columna 'date', puesto que no sera utilizada en el análisis posterior.
regression.drop('date', axis=1, inplace=True)
regression.head(10)

#Mostramos la cantidad de filas totales existentes en los datos a analizar.
print('Cantidad de filas: ', regression.shape[0])

#Empezamos a analizar los valores únicos

#Mostramos la columna 'bedrooms' del documento
regression['bedrooms'].unique()

#Mostramos la columna 'bathrooms' del documento 
regression['bathrooms'].unique()

#Mostramos la columna 'floors' del documento 
regression['floors'].unique()

#Mostramos la columna 'condition' del documento 
regression['condition'].unique()

#Mostramos la columna 'grade' del documento 
regression['grade'].unique()

#Ordenamos los datos en orden decreciente según el precio de la casa. 
regression.sort_values(by='price', ascending=False).head(10)['id'] 
#Mostramos los ids de las 10 casas más caras.

#Precio medio de las casas.
regression['price'].mean()

#Utilizamos la funcion 'groupby' y agrupamos los datos segun la columna 'bedrooms'.
#Calculamos el promedio de la columna 'price'
regression.groupby('bedrooms')['price'].mean()

#Agrupamos los datos segun la columna 'bedrooms' y calculamos el promedio de la columna 'sqft_living' 
regression.groupby('bedrooms')['sqft_living'].mean()

#Imprimimos el precio medio de las casas con 'waterfront'
regression[regression['waterfront']==1]['price'].mean()

#Imprimimos el precio medio de las casas sin 'waterfront'
regression[regression['waterfront']==0]['price'].mean()

#Observamos si existe alguna correlacion entre las variables 'condition' y 'grade' 
regression[['condition', 'grade']].corr()

#Dibujamos una gráfica para poder comprobar si hay correlación positiva, negativa o no hay correlacion alguna entre los datos.
sns.regplot(x='condition', y='grade', data=regression)
print("La grafica mostrada a continuación indica el estado de correlacion.")

print("Observamos que entre ambas variables, 'condition' y 'grade', existe una correlación positiva, por lo que a mayor condición del inmueble, mayor será su calificación. Esto tiene sentido, ya que un inmueble en buenas condiciones tendrá una mejor calificación si lo comparamos con uno en malas condiciones.")

#Mostramos las casas segun sus condiciones

#Cantidad de casas segun sus condiciones
regression['condition'].value_counts()

#Cantidad de casas por baños
regression['bathrooms'].value_counts()

#Cantidad de casas por pisos
regression['floors'].value_counts()

#Cantidad de casas por calificacion
regression['grade'].value_counts()

#Cantidad de casas por precio
regression['price'].value_counts()

#Un cliente nos pide que encontremos una casa con las siguientes categorias:

    #3 o 4 habitaciones
    #Más de 3 baños
    #1 planta
    #Sin tenga vistas al lago
    #Tiene que tener por lo menos un 3 de condición
    #La calificacion tiene que ser al menos de un 5
    #El precio tiene que ser menos de 300000

#Creamos una variable que contenga los datos de las casas que cumplen con las condiciones requeridas
regression[((regression['bedrooms']==3) | (regression['bedrooms']==4)) &  (regression['bathrooms']>3) &  (regression['floors']==1) & (regression['waterfront']==0) & (regression['condition']>=3) & (regression['grade']>=5) & (regression['price']<300000)]

print("No es posible recomendarle al cliente ninguna casa con las condiciones que ha solicitado, por lo tanto la lista se entrega vacia.")

#Mostramos las casas cuyo precio es el doble que la media
regression[regression['price']>(regression['price'].mean()*2)]

#Obtenemos la diferencia entre el precio medio de las casas con 3 habitaciones y las casas con 4 habitaciones
regression[regression['bedrooms']==4]['price'].mean() - regression[regression['bedrooms']==3]['price'].mean()

#Mostramos los distintos codigos postales
regression['zipcode'].unique()

#Mostramos las casas que han sido renovadas
regression[regression['yr_renovated']>0]

#Imprimimos los detalles de la 11º casa mas cara del dataset 
regression.sort_values(by='price', ascending=False).head(11).iloc[10]

print("Vamos a crear el modelo de regresion para segun unas carecteristicas imprimir el precio.")

plt.figure(figsize=(15, 10))

sns.set(style='white')

mask=np.triu(np.ones_like(regression.corr(), dtype=bool))

cmap=sns.diverging_palette(0, 10, as_cmap=True)


sns.heatmap(regression.corr(),
           mask=mask,
          cmap=cmap,
          center=0,
          square=True,
          annot=True,
          linewidths=0.5,
          cbar_kws={'shrink': 0.5});

print("A simple vista podemos observar que 'condition','waterfront' y 'lat', entre otras, tiene una correlacción muy baja con nuestra variable dependiente por lo que son candidatas a ser excluidas de nuestro set de entrenamiento, pero de momento vamos a dejarlas.")

print("El primer paso es separar los datos de entrenamiento de nuestro variable objetivo o variable dependiente")

X = regression.drop('price', axis=1)

y = regression.price

X.head()

print("Una vez que nos hemos decantado por estas variables ahora sí vamos a dividir nuestro set de datos en entrenamiento y test, para ello utilizamemos el método train_test_split de la libería scikit-learn")

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=22)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.preprocessing import StandardScaler, MinMaxScaler
sc = StandardScaler().fit(X_train)
mm = MinMaxScaler().fit(X_train)

print("Ahora con ellos podemos transformar nuestros set de datos y probarlos por separado para ver con cual de los dos funciona mejor, es importante realizar el ajuste del scaler únicamente con los datos train, con la intención de dar a nuestro modelo la menor información sobre los datos de test para que nuestro experimento sea lo más veraz posible")

X_train_sc = sc.transform(X_train)
X_test_sc = sc.transform(X_test)
X_train_mm = mm.transform(X_train)
X_test_mm = mm.transform(X_test)

X_train_sc.shape, X_train_mm.shape

X_train_sc.shape

X_train_sc

X_train_mm

print("Una vez que ya tenemos nuestros datos transfomados y escalados podemos proceder a entrenar nuestro modelo, para una primera aproximación vamos a decantarnos por el modelo más sencillo que es una regresión lineal")

from sklearn.linear_model import LinearRegression

ln = LinearRegression()
ln_sc = LinearRegression()
ln_mm = LinearRegression()

ln.fit(X_train, y_train)
ln_sc.fit(X_train_sc,y_train)
ln_mm.fit(X_train_mm,y_train)

print("Ahora comenzamos con las predicciones.")

preds =ln.predict(X_test)
preds_sc =ln_sc.predict(X_test_sc)
preds_mm = ln_mm.predict(X_test_mm)

preds[:10]

preds_sc[:10]

preds_mm[:10]

y_test[:10]

ln.score(X_train, y_train), ln_sc.score(X_train_sc, y_train), ln_mm.score(X_train_mm, y_train)

ln.score(X_test, y_test), ln_sc.score(X_test_sc, y_test), ln_mm.score(X_test_mm, y_test)

from sklearn.metrics import mean_squared_error as mse

mse(y_train, ln.predict(X_train), squared=False)

mse(y_test, preds, squared=False)